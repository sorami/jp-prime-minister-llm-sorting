## 実験の前提

### 使用モデルと歴代首相データ

OpenAIの[GPT-5 mini](https://developers.openai.com/api/docs/models/gpt-5-mini)（モデルID: `gpt-5-mini-2025-08-07`）を使用しました。Knowledge cutoff（いつまでのデータで学習されたか）は2024年5月31日です。

対象は初代の伊藤博文から、岸田文雄（~2024年10月1日）まで、64人の歴代内閣総理大臣です。複数回就任した首相（吉田茂、安倍晋三など）は1人として扱います。モデルのknowledge cutoff以降に就任した石破茂・高市早苗の両氏は対象外としました。

### 比較の軸

以下の6軸を定義しました。メインの実験は「左派↔右派」で行い、他の5軸はKwikSortによる参考ランキングを生成しています。

| 軸                          | 説明                                                                                     |
| :-------------------------- | :--------------------------------------------------------------------------------------- |
| **左派 ↔ 右派**             | 改革・変革を志向する左派的な政治姿勢か、伝統・秩序・現状維持を重視する右派的な政治姿勢か |
| トップダウン ↔ ボトムアップ | 強いリーダーシップで上から引っ張るタイプか、合意形成を重視し下から積み上げるタイプか     |
| ロマンチスト ↔ リアリスト   | 理想や信念を追い求めるタイプか、現実的・実利的な判断を重視するタイプか                   |
| 肉食系 ↔ 草食系             | 積極的・攻撃的・野心的な肉食系タイプか、穏やか・控えめ・受動的な草食系タイプか           |
| 犬っぽい ↔ 猫っぽい         | 忠実で人懐っこく集団行動を好む犬っぽい雰囲気か、独立心が強くマイペースな猫っぽい雰囲気か |
| 陰キャ ↔ 陽キャ             | 内向的・暗い・ひとりが好きな雰囲気か、外向的・明るい・社交的な雰囲気か                   |

### LLMへの入力情報

LLMへの入力情報は **「名前」のみ** です。Wikipedia記事も経歴テキストも一切与えていません。LLMが事前学習で獲得した知識だけで判断する設計です。

元記事では論文（タイトルとアブストラクト）やニュースなど「文章」が入力でしたが、今回は「固有名詞」だけです。入力テキストを解釈するのではなく、LLMが事前学習で蓄えた知識・世界観そのものが判断に反映されるという点で、性質が異なります。

### ソート手法と評価方法

本実験では以下の4手法を比較しました。

| 手法                        | 概要                            | 入出力       | 計算量        | API呼出数 |
| :-------------------------- | :------------------------------ | :----------- | :------------ | --------: |
| ポイントワイズ              | 各首相に0〜100点の絶対スコア    | 1名 → スコア | $O(N)$        |        64 |
| リストワイズ                | 64人全員を一括で並べ替え        | 64名 → 順序  | $O(1)$        |         1 |
| ペアワイズ - 総当たり勝利数 | 全C(64,2)=2,016ペアを双方向比較 | 2名 → 勝者   | $O(N^2)$      |     4,032 |
| ペアワイズ - KwikSort       | QuickSort式にピボット比較で分割 | 2名 → 勝者   | $O(N \log N)$ |  平均 361 |

ポイントワイズとペアワイズのプロンプトでは結論だけを出力させるのではなく、まず各人物についての考察を述べさせてから最後に回答させる **Chain of Thought（CoT）** 形式を採用しています。これにより、LLMがどのような知識・推論に基づいて判断したかを確認できます。加えて、OpenAI Responses APIの `reasoning` パラメータを `{"effort": "medium"}` に設定し、モデル内部の推論プロセス（thinking）も有効化しています（参考: [Reasoning models | OpenAI API](https://developers.openai.com/api/docs/guides/reasoning/)）。

各手法の”精度”は、ペアワイズ総当たりの勝利数ランキングをベースラインとし、**[ケンドールの順位相関係数](https://ja.wikipedia.org/wiki/%E3%82%B1%E3%83%B3%E3%83%89%E3%83%BC%E3%83%AB%E3%81%AE%E9%A0%86%E4%BD%8D%E7%9B%B8%E9%96%A2%E4%BF%82%E6%95%B0)**（Kendall τ: 2つのランキングの一致度。1で完全一致、0で無相関）で評価しています。
