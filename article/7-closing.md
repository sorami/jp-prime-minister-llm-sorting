## おわりに

各手法のベースライン（総当たり勝利数ソート）との一致度をまとめます。

| 手法                               | API呼出数 | Kendall τ |
| :--------------------------------- | --------: | --------: |
| ポイントワイズ（絶対スコア）       |        64 |      0.86 |
| リストワイズ（一括ランキング）     |         1 |      0.66 |
| KwikSort（100 seed平均）           |   avg 361 |      0.87 |
| ペアワイズ総当たり（ベースライン） |     4,032 |      1.00 |

ポイントワイズ法は64回のAPI呼び出しでτ 0.86と、平均361回のKwikSortに匹敵する一致度です。ただし0〜100点の離散スコアに64人を割り当てるため同率が大量に発生し（92%が同率）、細かい順位の区別には限界があります。リストワイズ法は1回のAPI呼び出しで済む手軽さが魅力ですが、τ 0.66と一致度は最も低く、個々の判断根拠も見えないため、精度と透明性に課題が残ります。

ペアワイズ総当たり（勝利数ソート）は4,032回とコストが大きいものの、双方向比較によりポジションバイアスが相殺され、推移律違反も1%強にとどまるなど、最も信頼性の高いランキングが得られました。KwikSortは総当たりの約18%の比較回数でτ 0.87を達成しており、コスト効率に優れます。ただしピボット選択によって中間ランクの順位が大きく変動しうる点（最大変動幅41）には注意が必要です。

今回はOpenAIのGPT-5 miniを使用しました。ClaudeやGeminiなど別のモデルでは、その"世界観"の違いから異なる結果が得られるかもしれません。

今回は「首相の名前」という固有名詞を入力としました。「都道府県」「ポケモン」「絵文字」「ジブリ作品タイトル」「Linuxコマンド」「HTTPステータスコード」なども題材として面白そうです。文章系では「百人一首」を手頃なデータセットとして思いつきましたが、LLMが学習時に全首を見ている可能性が高く、テキストの解釈というより固有表現的な判断になるかもしれません。

ふとした思いつきから始めた実験でしたが、「LLMでソート」という営みの奥深さを実感できました。

Enjoy sorting!
